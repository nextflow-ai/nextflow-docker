# ============================================================================
# NEXTFLOW DOCKER COMPOSE - H·ªÜ TH·ªêNG MICROSERVICES TO√ÄN DI·ªÜN
# ============================================================================
# M√¥ t·∫£: H·ªá th·ªëng NextFlow bao g·ªìm c√°c d·ªãch v·ª• AI, automation, monitoring,
#        v√† qu·∫£n l√Ω n·ªôi dung ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho m√¥i tr∆∞·ªùng production
# ============================================================================

# ƒê·ªäNH NGHƒ®A C√ÅC VOLUMES - L∆ØU TR·ªÆ D·ªÆ LI·ªÜU B·ªÄN V·ªÆNG
# ============================================================================
# Volumes ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu quan tr·ªçng c·ªßa c√°c service
# D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c b·∫£o to√†n ngay c·∫£ khi container b·ªã x√≥a ho·∫∑c kh·ªüi ƒë·ªông l·∫°i
volumes:
  # === D·ªäCH V·ª§ AI V√Ä AUTOMATION ===
  n8n_storage: # L∆∞u tr·ªØ workflows, credentials v√† d·ªØ li·ªáu n8n
  flowise: # L∆∞u tr·ªØ AI flows, chatbots v√† c·∫•u h√¨nh Flowise
  ollama_storage: # L∆∞u tr·ªØ c√°c m√¥ h√¨nh AI (LLM) ƒë√£ t·∫£i xu·ªëng
  qdrant_storage: # L∆∞u tr·ªØ vector embeddings cho t√¨m ki·∫øm semantic
  qdrant_snapshots: # L∆∞u tr·ªØ backup snapshots c·ªßa Qdrant
  open-webui: # L∆∞u tr·ªØ c·∫•u h√¨nh v√† d·ªØ li·ªáu giao di·ªán chat AI
  langflow_data: # L∆∞u tr·ªØ workflows v√† c·∫•u h√¨nh Langflow
  langflow_logs: # L∆∞u tr·ªØ logs c·ªßa Langflow
  # === C∆† S·ªû D·ªÆ LI·ªÜU ===
  postgres_storage: # L∆∞u tr·ªØ d·ªØ li·ªáu PostgreSQL (ch√≠nh)
  redis_data: # L∆∞u tr·ªØ cache v√† session Redis
  mariadb_data: # L∆∞u tr·ªØ d·ªØ li·ªáu MariaDB cho WordPress
  # === GI√ÅM S√ÅT V√Ä LOGGING ===
  prometheus_data: # L∆∞u tr·ªØ metrics v√† time-series data
  grafana_data: # L∆∞u tr·ªØ dashboards v√† c·∫•u h√¨nh Grafana
  loki_data: # L∆∞u tr·ªØ logs t·∫≠p trung t·ª´ t·∫•t c·∫£ services
  jaeger_data: # L∆∞u tr·ªØ distributed tracing data
  # === MESSAGING V√Ä QUEUE ===
  rabbitmq_data: # L∆∞u tr·ªØ messages v√† queue configuration
  # === QU·∫¢N L√ù M√É NGU·ªíN ===
  gitlab_config: # C·∫•u h√¨nh GitLab (c√≥ th·ªÉ d√πng bind mount)
  gitlab_logs: # Logs c·ªßa GitLab
  gitlab_data: # Repositories, issues, merge requests
  gitlab_backups: # Backup t·ª± ƒë·ªông c·ªßa GitLab
  # === MAIL SERVER ===
  stalwart_config: # C·∫•u h√¨nh Stalwart Mail Server
  stalwart_data: # D·ªØ li·ªáu email v√† mailboxes
  stalwart_logs: # Logs c·ªßa mail server
  # === QU·∫¢N L√ù N·ªòI DUNG ===
  wordpress_data:
    # Themes, plugins, uploads WordPress

    # ƒê·ªäNH NGHƒ®A M·∫†NG - NETWORK CONFIGURATION - ƒê√É T·ªêI ∆ØU H√ìA
    # ============================================================================
    # T·∫°o m·∫°ng bridge t·ªëi ∆∞u ƒë·ªÉ c√°c container c√≥ th·ªÉ giao ti·∫øp hi·ªáu qu·∫£
    # C·∫•u h√¨nh m·∫°ng ƒë∆∞·ª£c t·ªëi ∆∞u cho performance v√† service discovery
networks:
  demo:
    driver: bridge # S·ª≠ d·ª•ng bridge driver cho m·∫°ng n·ªôi b·ªô
    name: nextflow_network # T√™n m·∫°ng r√µ r√†ng
    driver_opts:
      # T·ªëi ∆∞u network performance
      com.docker.network.bridge.name: nextflow0 # T√™n bridge interface
      com.docker.network.bridge.enable_icc: "true" # B·∫≠t inter-container communication
      com.docker.network.bridge.enable_ip_masquerade: "true" # B·∫≠t IP masquerading
      com.docker.network.bridge.host_binding_ipv4: "0.0.0.0" # Bind t·∫•t c·∫£ interfaces
      com.docker.network.driver.mtu: "1500" # Maximum Transmission Unit t·ªëi ∆∞u
    ipam:
      # IP Address Management - T·ªëi ∆∞u h√≥a
      driver: default
      config:
        - subnet: 172.20.0.0/16 # D·∫£i IP cho m·∫°ng n·ªôi b·ªô (65534 IPs)
          gateway: 172.20.0.1 # Gateway m·∫∑c ƒë·ªãnh
          ip_range: 172.20.1.0/24 # D·∫£i IP cho containers (254 IPs)
      options:
        # T·ªëi ∆∞u IPAM performance
        com.docker.network.enable_ipv6: "false" # T·∫Øt IPv6 ƒë·ªÉ tƒÉng performance
        com.docker.network.bridge.default_bridge: "false" # Kh√¥ng d√πng default bridge

# C·∫§U H√åNH M·∫∂C ƒê·ªäNH CHO T·∫§T C·∫¢ SERVICES - ƒê√É T·ªêI ∆ØU H√ìA
# ============================================================================
# Template n√†y s·∫Ω ƒë∆∞·ª£c k·∫ø th·ª´a b·ªüi t·∫•t c·∫£ services ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n
x-default-opts: &default-opts
  restart: unless-stopped # T·ª± ƒë·ªông kh·ªüi ƒë·ªông l·∫°i khi container b·ªã l·ªói (tr·ª´ khi d·ª´ng th·ªß c√¥ng)
  networks: [ 'demo' ] # K·∫øt n·ªëi t·∫•t c·∫£ services v√†o m·∫°ng chung
  logging:
    # C·∫•u h√¨nh logging th·ªëng nh·∫•t - T·ªêI ∆ØU H√ìA
    driver: "json-file" # S·ª≠ d·ª•ng JSON format cho logs
    options:
      max-size: "50m" # TƒÉng t·ª´ 10m l√™n 50MB ƒë·ªÉ gi·∫£m I/O
      max-file: "5" # TƒÉng t·ª´ 3 l√™n 5 file log (rotation)
      compress: "true" # N√©n logs c≈© ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng
      # T·ªëi ∆∞u logging performance
      mode: "non-blocking" # Logging kh√¥ng ch·∫∑n (non-blocking)
      max-buffer-size: "4m" # Buffer t·ªëi ƒëa 4MB
  # C·∫•u h√¨nh chung cho t·∫•t c·∫£ services
  security_opt:
    - no-new-privileges:true # B·∫£o m·∫≠t: kh√¥ng cho ph√©p escalate privileges
  read_only: false # Cho ph√©p ghi v√†o filesystem (c·∫ßn thi·∫øt cho h·∫ßu h·∫øt services)
  tmpfs:
    - /tmp:noexec,nosuid,size=100m # Temporary filesystem t·ªëi ∆∞u

# C·∫§U H√åNH TEMPLATE CHO N8N SERVICES
# ============================================================================
# Template chung cho t·∫•t c·∫£ c√°c instance c·ªßa n8n (main, worker, webhook)
# ƒê·∫£m b·∫£o c·∫•u h√¨nh nh·∫•t qu√°n v√† d·ªÖ b·∫£o tr√¨
x-n8n: &service-n8n
  <<: *default-opts # K·∫ø th·ª´a c·∫•u h√¨nh m·∫∑c ƒë·ªãnh
  image: n8nio/n8n:latest
  environment:
    # === C·∫§U H√åNH C·ªû S·ªû D·ªÆ LI·ªÜU ===
    - DB_TYPE=postgresdb # Lo·∫°i database
    - DB_POSTGRESDB_HOST=postgres # Host PostgreSQL
    - DB_POSTGRESDB_USER=${POSTGRES_USER} # Username database
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} # Password database
    - DB_POSTGRESDB_DATABASE=nextflow_n8n # T√™n database ri√™ng cho n8n
    # === C·∫§U H√åNH B·∫¢O M·∫¨T ===
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY} # Kh√≥a m√£ h√≥a cho credentials
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET} # JWT secret cho x√°c th·ª±c
    # === C·∫§U H√åNH CH·ª®C NƒÇNG ===
    - N8N_DIAGNOSTICS_ENABLED=false # T·∫Øt g·ª≠i d·ªØ li·ªáu ch·∫©n ƒëo√°n v·ªÅ n8n.io
    - N8N_PERSONALIZATION_ENABLED=false # T·∫Øt thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n h√≥a
    - WEBHOOK_URL=${N8N_URL} # URL webhook t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
    # === C·∫§U H√åNH REDIS QUEUE ===
    - QUEUE_BULL_REDIS_HOST=redis # Host Redis cho queue
    - QUEUE_BULL_REDIS_PASSWORD=${REDIS_PASSWORD:-nextflow@2025} # Password Redis
  # === DEPENDENCIES - PH·ª§ THU·ªòC ===
  depends_on:
    postgres:
      condition: service_healthy # ƒê·ª£i PostgreSQL s·∫µn s√†ng
    redis:
      condition: service_healthy # ƒê·ª£i Redis s·∫µn s√†ng

# C·∫§U H√åNH TEMPLATE CHO OLLAMA SERVICES
# ============================================================================
# Template cho Ollama - C√¥ng c·ª• ch·∫°y m√¥ h√¨nh AI ng√¥n ng·ªØ l·ªõn (LLM) tr√™n m√°y local
# LLM = Large Language Model (M√¥ h√¨nh ng√¥n ng·ªØ l·ªõn)
# Inference engine = C√¥ng c·ª• suy lu·∫≠n AI
# H·ªó tr·ª£ c·∫£ CPU v√† GPU, t·ª± ƒë·ªông t·∫£i c√°c m√¥ h√¨nh AI c·∫ßn thi·∫øt
x-ollama: &service-ollama
  <<: *default-opts
  image: ollama/ollama:latest
  volumes:
    - ollama_storage:/root/.ollama # L∆∞u tr·ªØ m√¥ h√¨nh AI ƒë√£ t·∫£i (c√≥ th·ªÉ r·∫•t l·ªõn)
  environment:
    - OLLAMA_ORIGINS=* # Cho ph√©p CORS (Cross-Origin Resource Sharing - Chia s·∫ª t√†i nguy√™n gi·ªØa c√°c domain) t·ª´ m·ªçi ngu·ªìn
    - OLLAMA_HOST=0.0.0.0 # L·∫Øng nghe tr√™n t·∫•t c·∫£ giao di·ªán m·∫°ng (interfaces)
  # L∆ØU √ù: Kh√¥ng s·ª≠ d·ª•ng healthcheck v√¨ Ollama image thi·∫øu c√°c c√¥ng c·ª• ki·ªÉm tra c·∫ßn thi·∫øt
  # Thay v√†o ƒë√≥ s·ª≠ d·ª•ng depends_on v√† startup delay (ƒë·ªô tr·ªÖ kh·ªüi ƒë·ªông)

  # C·∫§U H√åNH TEMPLATE CHO VI·ªÜC T·∫¢I M√î H√åNH OLLAMA
  # ============================================================================
  # Service kh·ªüi t·∫°o (init service) ƒë·ªÉ t·ª± ƒë·ªông t·∫£i c√°c m√¥ h√¨nh AI c·∫ßn thi·∫øt
  # Ch·∫°y m·ªôt l·∫ßn sau khi Ollama kh·ªüi ƒë·ªông th√†nh c√¥ng
x-init-ollama: &init-ollama
  <<: *default-opts
  image: ollama/ollama:latest
  volumes:
    - ollama_storage:/root/.ollama # Chia s·∫ª b·ªô nh·ªõ l∆∞u tr·ªØ v·ªõi Ollama ch√≠nh
  entrypoint: /bin/sh # S·ª≠ d·ª•ng shell (giao di·ªán d√≤ng l·ªánh) ƒë·ªÉ ch·∫°y script
  extra_hosts:
    - "host.docker.internal:host-gateway" # Cho ph√©p truy c·∫≠p m√°y ch·ªß host n·∫øu c·∫ßn
  environment:
    - OLLAMA_HOST=ollama:11434 # K·∫øt n·ªëi ƒë·∫øn Ollama service
  command:
    - "-c"
    - |
      # === SCRIPT T·ª∞ ƒê·ªòNG T·∫¢I M√î H√åNH AI ===
      echo "üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh t·∫£i m√¥ h√¨nh AI..."

      # ƒê·ª£i Ollama service kh·ªüi ƒë·ªông ho√†n to√†n
      echo "‚è≥ ƒê·ª£i Ollama kh·ªüi ƒë·ªông (30 gi√¢y)..."
      sleep 30

      # Ki·ªÉm tra k·∫øt n·ªëi v·ªõi Ollama
      echo "üîç Ki·ªÉm tra k·∫øt n·ªëi v·ªõi Ollama..."
      for i in {1..10}; do
        if OLLAMA_HOST=ollama:11434 ollama list >/dev/null 2>&1; then
          echo "‚úÖ K·∫øt n·ªëi th√†nh c√¥ng v·ªõi Ollama!"
          break
        fi
        echo "‚ùå L·∫ßn th·ª≠ $i th·∫•t b·∫°i, ƒë·ª£i th√™m 10 gi√¢y..."
        sleep 10
      done

      # T·∫£i c√°c m√¥ h√¨nh AI c·∫ßn thi·∫øt
      echo "üì• B·∫Øt ƒë·∫ßu t·∫£i c√°c m√¥ h√¨nh AI..."

      # M√¥ h√¨nh ch√≠nh cho chat v√† completion (ho√†n th√†nh vƒÉn b·∫£n)
      echo "üì• ƒêang t·∫£i Llama 3.1 (m√¥ h√¨nh ch√≠nh cho tr√≤ chuy·ªán)..."
      OLLAMA_HOST=ollama:11434 ollama pull llama3.1

      # M√¥ h√¨nh embedding (nh√∫ng vƒÉn b·∫£n th√†nh vector) cho t√¨m ki·∫øm ng·ªØ nghƒ©a
      echo "üì• ƒêang t·∫£i Nomic Embed Text (chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector)..."
      OLLAMA_HOST=ollama:11434 ollama pull nomic-embed-text

      # M√¥ h√¨nh nh·∫π cho c√°c t√°c v·ª• ƒë∆°n gi·∫£n
      echo "üì• ƒêang t·∫£i Gemma 2:2B (m√¥ h√¨nh nh·∫π - 2 t·ª∑ tham s·ªë)..."
      OLLAMA_HOST=ollama:11434 ollama pull gemma2:2b

      # M√¥ h√¨nh reasoning (suy lu·∫≠n logic) m·ªõi
      echo "üì• ƒêang t·∫£i DeepSeek R1:7B (m√¥ h√¨nh suy lu·∫≠n - 7 t·ª∑ tham s·ªë)..."
      OLLAMA_HOST=ollama:11434 ollama pull deepseek-r1:7b

      echo "üéâ Ho√†n th√†nh t·∫£i t·∫•t c·∫£ m√¥ h√¨nh AI!"
      echo "üìã Danh s√°ch m√¥ h√¨nh ƒë√£ t·∫£i:"
      OLLAMA_HOST=ollama:11434 ollama list

# ============================================================================
# ƒê·ªäNH NGHƒ®A C√ÅC SERVICES - MICROSERVICES ARCHITECTURE
# ============================================================================
# T·∫•t c·∫£ c√°c d·ªãch v·ª• ƒë∆∞·ª£c t·ªï ch·ª©c theo nh√≥m ch·ª©c nƒÉng ƒë·ªÉ d·ªÖ qu·∫£n l√Ω
# M·ªói service c√≥ c·∫•u h√¨nh t·ªëi ∆∞u cho production environment

services:
  # ============================================================================
  # NH√ìM D·ªäCH V·ª§ AI V√Ä AUTOMATION
  # ============================================================================
  # FLOWISE - C√îNG C·ª§ X√ÇY D·ª∞NG LU·ªíNG C√îNG VI·ªÜC AI B·∫∞NG GIAO DI·ªÜN K√âO TH·∫¢
  flowise:
    <<: *default-opts
    image: flowiseai/flowise:latest
    container_name: flowise
    hostname: flowise # T√™n m√°y ch·ªß r√µ r√†ng cho service discovery (kh√°m ph√° d·ªãch v·ª•)
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # C·∫•u h√¨nh c∆° b·∫£n
      - PORT=3000 # Port internal c·ªßa Flowise
      - NODE_ENV=production # Ch·∫ø ƒë·ªô production
      # X√°c th·ª±c v√† b·∫£o m·∫≠t
      - FLOWISE_USERNAME=${FLOWISE_USERNAME:-admin} # Username ƒëƒÉng nh·∫≠p
      - FLOWISE_PASSWORD=${FLOWISE_PASSWORD:-password} # Password ƒëƒÉng nh·∫≠p
      - FLOWISE_SECRETKEY_OVERWRITE=${FLOWISE_SECRET_KEY:-your-secret-key} # Secret key
      # C·∫•u h√¨nh Redis cache
      - REDIS_HOST=redis # Host Redis
      - REDIS_PORT=6379 # Port Redis
      - REDIS_PASSWORD=${REDIS_PASSWORD:-nextflow@2025} # Password Redis
      # C·∫•u h√¨nh database (n·∫øu c·∫ßn)
      - DATABASE_TYPE=sqlite # S·ª≠ d·ª•ng SQLite cho ƒë∆°n gi·∫£n
      - DATABASE_PATH=/root/.flowise # ƒê∆∞·ªùng d·∫´n database
      # C·∫•u h√¨nh logging
      - LOG_LEVEL=info # M·ª©c ƒë·ªô logging
      - LOG_PATH=/root/.flowise/logs # ƒê∆∞·ªùng d·∫´n logs
    # === PORT MAPPING ===
    ports:
      - "4001:3000" # Expose port 3000 ra host:4001
    # === NETWORK CONFIGURATION ===
    extra_hosts:
      - "host.docker.internal:host-gateway" # Cho ph√©p truy c·∫≠p host
    # === VOLUME MOUNTS ===
    volumes:
      - flowise:/root/.flowise # Persistent storage cho Flowise
      - ./shared:/data/shared # Shared folder v·ªõi host
    # === STARTUP CONFIGURATION ===
    entrypoint: /bin/sh -c "sleep 3; flowise start" # Delay nh·ªè ƒë·ªÉ tr√°nh race condition
    # === DEPENDENCIES ===
    depends_on:
      redis:
        condition: service_healthy # ƒê·ª£i Redis s·∫µn s√†ng
    # === HEALTH CHECK ===
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/v1/ping" ]
      interval: 30s # Ki·ªÉm tra m·ªói 30 gi√¢y
      timeout: 10s # Timeout sau 10 gi√¢y
      retries: 3 # Th·ª≠ l·∫°i 3 l·∫ßn
      start_period: 60s # ƒê·ª£i 60 gi√¢y tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu check
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '2' # T·ªëi ƒëa 2 CPU cores
          memory: 4G # T·ªëi ƒëa 4GB RAM
        reservations:
          cpus: '0.5' # ƒê·∫£m b·∫£o √≠t nh·∫•t 0.5 CPU
          memory: 1G # ƒê·∫£m b·∫£o √≠t nh·∫•t 1GB RAM
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=true" # Enable Traefik routing (n·∫øu d√πng)
      - "service.group=ai" # Nh√≥m service AI
      - "service.type=frontend" # Lo·∫°i service

  # OPEN WEBUI - GIAO DI·ªÜN CHAT HI·ªÜN ƒê·∫†I CHO AI
  # ----------------------------------------------------------------------------
  open-webui:
    <<: *default-opts
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    hostname: open-webui # T√™n m√°y ch·ªß cho kh√°m ph√° d·ªãch v·ª•
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # C·∫•u h√¨nh Ollama connection
      - OLLAMA_BASE_URL=http://ollama:11434 # URL k·∫øt n·ªëi ƒë·∫øn Ollama
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET_KEY:-your-secret-key} # Secret key
      # C·∫•u h√¨nh authentication
      - WEBUI_AUTH=true # B·∫≠t x√°c th·ª±c
      - DEFAULT_USER_ROLE=user # Role m·∫∑c ƒë·ªãnh cho user m·ªõi
      # C·∫•u h√¨nh features
      - ENABLE_SIGNUP=true # Cho ph√©p ƒëƒÉng k√Ω user m·ªõi
      - ENABLE_LOGIN_FORM=true # Hi·ªÉn th·ªã form ƒëƒÉng nh·∫≠p
      - ENABLE_WEB_SEARCH=false # T·∫Øt web search (c√≥ th·ªÉ b·∫≠t sau)
      # C·∫•u h√¨nh file upload
      - ENABLE_IMAGE_GENERATION=true # B·∫≠t t·∫°o ·∫£nh (n·∫øu model h·ªó tr·ª£)
      - MAX_FILE_SIZE=10485760 # Gi·ªõi h·∫°n file upload 10MB
      # C·∫•u h√¨nh logging
      - LOG_LEVEL=INFO # M·ª©c ƒë·ªô logging
    # === PORT MAPPING ===
    ports:
      - "5080:8080" # Expose port 8080 ra host:5080
    # === VOLUME MOUNTS ===
    volumes:
      - open-webui:/app/backend/data # Persistent storage
      - ./shared:/data/shared # Shared folder cho file uploads
    # === DEPENDENCIES ===
    # depends_on:
    #   - ollama-cpu                  # Ph·ª• thu·ªôc v√†o Ollama (CPU version) - Commented ƒë·ªÉ tr√°nh l·ªói khi kh√¥ng d√πng profile cpu
    # === HEALTH CHECK ===
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 30s # Ki·ªÉm tra m·ªói 30 gi√¢y
      timeout: 10s # Timeout sau 10 gi√¢y
      retries: 3 # Th·ª≠ l·∫°i 3 l·∫ßn
      start_period: 30s # ƒê·ª£i 30 gi√¢y tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu check
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '2' # T·ªëi ƒëa 2 CPU cores
          memory: 3G # T·ªëi ƒëa 3GB RAM
        reservations:
          cpus: '0.5' # ƒê·∫£m b·∫£o √≠t nh·∫•t 0.5 CPU
          memory: 1G # ƒê·∫£m b·∫£o √≠t nh·∫•t 1GB RAM
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=true" # Enable Traefik routing
      - "service.group=ai" # Nh√≥m service AI
      - "service.type=frontend" # Lo·∫°i service

  # POSTGRESQL - M√ÅY CH·ª¶ C∆† S·ªû D·ªÆ LI·ªÜU CH√çNH
  # ----------------------------------------------------------------------------
  postgres:
    <<: *default-opts
    image: postgres:16-alpine # Phi√™n b·∫£n Alpine (nh·∫π v√† b·∫£o m·∫≠t)
    container_name: postgres
    hostname: postgres # T√™n m√°y ch·ªß cho kh√°m ph√° d·ªãch v·ª•
    restart: always
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # Database configuration
      POSTGRES_USER: ${POSTGRES_USER:-nextflow} # User ch√≠nh
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-nextflow@2025} # Password
      POSTGRES_DB: ${POSTGRES_DB:-nextflow} # Database ch√≠nh
      POSTGRES_MULTIPLE_DATABASES: ${POSTGRES_MULTIPLE_DATABASES:-nextflow_n8n,nextflow_gitlab}
      PGDATA: /var/lib/postgresql/data/pgdata # Data directory
      # PostgreSQL specific settings
      POSTGRES_INITDB_ARGS: --encoding=UTF-8 --lc-collate=C --lc-ctype=C # Init args
      # T·ªëi ∆∞u hi·ªáu nƒÉng (Performance tuning) - ƒê√É T·ªêI ∆ØU H√ìA
      POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements # Th∆∞ vi·ªán m·ªü r·ªông th·ªëng k√™
      POSTGRES_MAX_CONNECTIONS: 300 # TƒÉng t·ª´ 200 l√™n 300 k·∫øt n·ªëi ƒë·ªìng th·ªùi
      POSTGRES_SHARED_BUFFERS: 1GB # TƒÉng t·ª´ 256MB l√™n 1GB b·ªô nh·ªõ ƒë·ªám chia s·∫ª
      POSTGRES_EFFECTIVE_CACHE_SIZE: 4GB # TƒÉng t·ª´ 1GB l√™n 4GB cache h·ªá th·ªëng
      POSTGRES_WORK_MEM: 16MB # TƒÉng t·ª´ 4MB l√™n 16MB b·ªô nh·ªõ l√†m vi·ªác
      POSTGRES_MAINTENANCE_WORK_MEM: 256MB # TƒÉng t·ª´ 64MB l√™n 256MB b·ªô nh·ªõ b·∫£o tr√¨      
      # T·ªëi ∆∞u WAL (Write-Ahead Logging) v√† Checkpoint
      POSTGRES_WAL_BUFFERS: 16MB # B·ªô nh·ªõ ƒë·ªám WAL
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9 # M·ª•c ti√™u ho√†n th√†nh checkpoint
      POSTGRES_CHECKPOINT_TIMEOUT: 15min # Th·ªùi gian timeout checkpoint
      POSTGRES_MAX_WAL_SIZE: 2GB # K√≠ch th∆∞·ªõc t·ªëi ƒëa WAL
      POSTGRES_MIN_WAL_SIZE: 1GB # K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu WAL      
      # T·ªëi ∆∞u Query Planning v√† Statistics
      POSTGRES_DEFAULT_STATISTICS_TARGET: 100 # M·ª•c ti√™u th·ªëng k√™ m·∫∑c ƒë·ªãnh
      POSTGRES_RANDOM_PAGE_COST: 1.1 # Chi ph√≠ truy c·∫≠p ng·∫´u nhi√™n (SSD)
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200 # ƒê·ªìng th·ªùi I/O hi·ªáu qu·∫£      
      # T·ªëi ∆∞u Connection v√† Background Processes
      POSTGRES_MAX_WORKER_PROCESSES: 8 # S·ªë worker processes t·ªëi ƒëa
      POSTGRES_MAX_PARALLEL_WORKERS: 8 # S·ªë parallel workers t·ªëi ƒëa
      POSTGRES_MAX_PARALLEL_WORKERS_PER_GATHER: 4 # Workers per gather node
      # C·∫•u h√¨nh ghi log
      POSTGRES_LOG_STATEMENT: mod # Ghi log c√°c thay ƒë·ªïi d·ªØ li·ªáu
      POSTGRES_LOG_MIN_DURATION_STATEMENT: 1000 # Ghi log truy v·∫•n ch·∫≠m (>1 gi√¢y)
      POSTGRES_LOG_CHECKPOINTS: on # Ghi log checkpoint (ƒëi·ªÉm ki·ªÉm tra)
      POSTGRES_LOG_CONNECTIONS: on # Ghi log k·∫øt n·ªëi
      POSTGRES_LOG_DISCONNECTIONS: on # Ghi log ng·∫Øt k·∫øt n·ªëi
    # === PORT MAPPING ===
    ports:
      - "5432:5432" # Standard PostgreSQL port
    # === VOLUME MOUNTS ===
    volumes:
      - postgres_storage:/var/lib/postgresql/data # Persistent data
      - ./postgres/init:/docker-entrypoint-initdb.d # Init scripts
      - ./postgres/conf:/etc/postgresql # Custom config
      - ./postgres/logs:/var/log/postgresql # Log files
    # === HEALTH CHECK ===
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-nextflow} -d ${POSTGRES_DB:-nextflow}" ]
      interval: 30s # Ki·ªÉm tra m·ªói 30 gi√¢y
      timeout: 10s # Timeout sau 10 gi√¢y
      retries: 10 # Th·ª≠ l·∫°i 10 l·∫ßn (database c·∫ßn th·ªùi gian)
      start_period: 60s # ƒê·ª£i 60 gi√¢y tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu check
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '4' # T·ªëi ƒëa 4 CPU cores
          memory: 6G # T·ªëi ƒëa 6GB RAM
        reservations:
          cpus: '1' # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 CPU
          memory: 2G # ƒê·∫£m b·∫£o √≠t nh·∫•t 2GB RAM
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=false" # Kh√¥ng expose qua Traefik
      - "service.group=database" # Nh√≥m service database
      - "service.type=backend" # Lo·∫°i service backend
      - "backup.enable=true" # Enable backup cho service n√†y
  # N8N - N·ªÄN T·∫¢NG T·ª∞ ƒê·ªòNG H√ìA LU·ªíNG C√îNG VI·ªÜC
  # ----------------------------------------------------------------------------
  # N·ªÅn t·∫£ng t·ª± ƒë·ªông h√≥a workflow (lu·ªìng c√¥ng vi·ªác) m·∫°nh m·∫Ω v·ªõi giao di·ªán k√©o th·∫£
  # K·∫øt n·ªëi v√† t·ª± ƒë·ªông h√≥a c√°c ·ª©ng d·ª•ng, d·ªãch v·ª• v√† APIs
  # Ghi ch√∫: n8n-import service ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè v√¨ ch·∫°y r·∫•t ch·∫≠m khi kh·ªüi ƒë·ªông l·∫°i Docker
  n8n:
    <<: *service-n8n # K·∫ø th·ª´a template c·∫•u h√¨nh n8n
    container_name: n8n
    hostname: n8n # T√™n m√°y ch·ªß cho kh√°m ph√° d·ªãch v·ª•
    # === PORT MAPPING ===
    ports:
      - "7856:5678" # Custom port 7856 thay v√¨ port m·∫∑c ƒë·ªãnh 5678
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # === C∆† S·ªû D·ªÆ LI·ªÜU ===
      - DB_TYPE=postgresdb # Lo·∫°i database
      - DB_POSTGRESDB_HOST=postgres # PostgreSQL host
      - DB_POSTGRESDB_USER=${POSTGRES_USER} # Database user
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} # Database password
      - DB_POSTGRESDB_DATABASE=nextflow_n8n # Database name
      # === B·∫¢O M·∫¨T & X√ÅC TH·ª∞C ===
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY} # Kh√≥a m√£ h√≥a workflows
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET} # JWT secret
      - WEBHOOK_URL=${N8N_URL} # URL webhook public
      # === C·∫§U H√åNH REDIS QUEUE (H√ÄNG ƒê·ª¢I) ===
      - QUEUE_BULL_REDIS_HOST=redis # M√°y ch·ªß Redis cho h√†ng ƒë·ª£i t√°c v·ª•
      - QUEUE_BULL_REDIS_PASSWORD=${REDIS_PASSWORD:-nextflow@2025} # M·∫≠t kh·∫©u Redis
      # === CH·ª®C NƒÇNG & T√çNH NƒÇNG ===
      - N8N_DIAGNOSTICS_ENABLED=false # T·∫Øt g·ª≠i d·ªØ li·ªáu ch·∫©n ƒëo√°n v·ªÅ n8n.io
      - N8N_PERSONALIZATION_ENABLED=false # T·∫Øt thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n h√≥a
      - N8N_METRICS_ENABLED=true # B·∫≠t metrics (s·ªë li·ªáu) cho gi√°m s√°t
      - N8N_HIRING_BANNER_ENABLED=false # T·∫Øt banner qu·∫£ng c√°o tuy·ªÉn d·ª•ng
      - N8N_VERSION_NOTIFICATIONS_ENABLED=false # T·∫Øt th√¥ng b√°o phi√™n b·∫£n m·ªõi
      - N8N_TEMPLATES_ENABLED=true # B·∫≠t m·∫´u workflow c√≥ s·∫µn
      - N8N_TEMPLATES_HOST=https://api.n8n.io/ # M√°y ch·ªß cung c·∫•p m·∫´u workflow
      - N8N_CACHE_ENABLED=true # B·∫≠t b·ªô nh·ªõ ƒë·ªám ƒë·ªÉ tƒÉng hi·ªáu nƒÉng
      # === M·∫†NG & GIAO TI·∫æP ===
      - N8N_PUSH_BACKEND=websocket # S·ª≠ d·ª•ng websocket cho giao ti·∫øp th·ªùi gian th·ª±c
      - N8N_EDITOR_BASE_URL=https://n8n.nextflow.vn # URL c∆° s·ªü cho tr√¨nh ch·ªânh s·ª≠a
      - N8N_HOST=n8n.nextflow.vn # T√™n m√°y ch·ªß c√¥ng khai
      - N8N_PROTOCOL=https # Giao th·ª©c HTTPS b·∫£o m·∫≠t
      - N8N_PORT=5678 # C·ªïng n·ªôi b·ªô
      # === RUNTIME CONFIGURATION ===
      - NODE_ENV=production # Ch·∫ø ƒë·ªô production
      - EXECUTIONS_PROCESS=main # X·ª≠ l√Ω executions trong main process
      - GENERIC_TIMEZONE=Asia/Ho_Chi_Minh # M√∫i gi·ªù Vi·ªát Nam
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true # T·ª± ƒë·ªông s·ª≠a file permissions
      # === LOGGING ===
      - N8N_LOG_LEVEL=info # M·ª©c ƒë·ªô logging
      - N8N_LOG_OUTPUT=console # Output logs ra console
    # === VOLUME MOUNTS ===
    volumes:
      - n8n_storage:/home/node/.n8n # Persistent n8n data
      - ./n8n/backup:/backup # Backup directory
      - ./shared:/data/shared # Shared files access
      - ./n8n/workflows:/home/node/workflows # Workflow templates
      - ./n8n/credentials:/home/node/credentials # Credential templates
    # === DEPENDENCIES ===
    depends_on:
      postgres:
        condition: service_healthy # ƒê·ª£i PostgreSQL s·∫µn s√†ng
      redis:
        condition: service_healthy # ƒê·ª£i Redis s·∫µn s√†ng
    # === HEALTH CHECK ===
    # Note: T·∫°m th·ªùi t·∫Øt health check v√¨ n8n kh√¥ng c√≥ endpoint /healthz ·ªïn ƒë·ªãnh
    # v√† c√≥ th·ªÉ g√¢y l·ªói k·∫øt n·ªëi trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p
    # healthcheck:
    #   test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5678/" ]
    #   interval: 60s
    #   timeout: 15s
    #   retries: 3
    #   start_period: 120s
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '4' # T·ªëi ƒëa 4 CPU cores
          memory: 6G # T·ªëi ƒëa 6GB RAM
        reservations:
          cpus: '4' # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 CPU
          memory: 4G # ƒê·∫£m b·∫£o √≠t nh·∫•t 2GB RAM
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=true" # Enable Traefik routing
      - "service.group=automation" # Nh√≥m service automation
      - "service.type=frontend" # Lo·∫°i service frontend
      - "backup.enable=true" # Enable backup workflows

  # QDRANT - C∆† S·ªû D·ªÆ LI·ªÜU VECTOR CHO AI EMBEDDINGS
  # ----------------------------------------------------------------------------
  qdrant:
    <<: *default-opts
    image: qdrant/qdrant:latest
    container_name: qdrant
    hostname: qdrant # T√™n m√°y ch·ªß cho kh√°m ph√° d·ªãch v·ª•
    # === C·∫§U H√åNH ENVIRONMENT - ƒê√É T·ªêI ∆ØU H√ìA ===
    environment:
      # C·∫•u h√¨nh d·ªãch v·ª• Qdrant
      - QDRANT__SERVICE__HTTP_PORT=6333 # C·ªïng HTTP API
      - QDRANT__SERVICE__GRPC_PORT=6334 # C·ªïng gRPC (giao th·ª©c RPC hi·ªáu nƒÉng cao)
      - QDRANT__LOG_LEVEL=INFO # M·ª©c ƒë·ªô ghi log
      # C·∫•u h√¨nh l∆∞u tr·ªØ
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage # ƒê∆∞·ªùng d·∫´n l∆∞u tr·ªØ d·ªØ li·ªáu
      - QDRANT__STORAGE__SNAPSHOTS_PATH=/qdrant/snapshots # ƒê∆∞·ªùng d·∫´n l∆∞u b·∫£n sao l∆∞u
      - QDRANT__STORAGE__ON_DISK_PAYLOAD=true # L∆∞u payload (d·ªØ li·ªáu k√®m theo) tr√™n ƒëƒ©a
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8 # S·ªë threads t√¨m ki·∫øm t·ªëi ƒëa
      - QDRANT__STORAGE__PERFORMANCE__MAX_OPTIMIZATION_THREADS=4 # Threads t·ªëi ∆∞u h√≥a      
      # T·ªëi ∆∞u hi·ªáu nƒÉng - N√ÇNG CAO
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=64 # TƒÉng t·ª´ 32MB l√™n 64MB
      - QDRANT__SERVICE__MAX_WORKERS=8 # TƒÉng t·ª´ 0 l√™n 8 workers c·ªë ƒë·ªãnh
      - QDRANT__STORAGE__WAL_CAPACITY_MB=128 # TƒÉng t·ª´ 32MB l√™n 128MB WAL
      - QDRANT__STORAGE__WAL_SEGMENTS_AHEAD=2 # TƒÉng t·ª´ 0 l√™n 2 segments d·ª± tr·ªØ
      - QDRANT__STORAGE__OPTIMIZERS__DELETED_THRESHOLD=0.2 # Ng∆∞·ª°ng x√≥a t·ªëi ∆∞u
      - QDRANT__STORAGE__OPTIMIZERS__VACUUM_MIN_VECTOR_NUMBER=1000 # S·ªë vector t·ªëi thi·ªÉu ƒë·ªÉ vacuum
      - QDRANT__STORAGE__OPTIMIZERS__DEFAULT_SEGMENT_NUMBER=2 # S·ªë segment m·∫∑c ƒë·ªãnh
      - QDRANT__STORAGE__OPTIMIZERS__MAX_SEGMENT_SIZE_MB=100 # K√≠ch th∆∞·ªõc segment t·ªëi ƒëa
      - QDRANT__STORAGE__OPTIMIZERS__MEMMAP_THRESHOLD_MB=200 # Ng∆∞·ª°ng memory mapping
      - QDRANT__STORAGE__OPTIMIZERS__INDEXING_THRESHOLD_MB=100 # Ng∆∞·ª°ng indexing      
      # T·ªëi ∆∞u Vector Search Performance
      - QDRANT__STORAGE__HNSW__M=16 # S·ªë k·∫øt n·ªëi HNSW (Higher = better recall)
      - QDRANT__STORAGE__HNSW__EF_CONSTRUCT=200 # EF construction parameter
      - QDRANT__STORAGE__HNSW__FULL_SCAN_THRESHOLD=10000 # Ng∆∞·ª°ng full scan
      - QDRANT__STORAGE__HNSW__MAX_INDEXING_THREADS=4 # Threads indexing t·ªëi ƒëa      
      # T·ªëi ∆∞u Memory v√† Cache
      - QDRANT__STORAGE__QUANTIZATION__ALWAYS_RAM=true # Lu√¥n gi·ªØ quantization trong RAM
      - QDRANT__STORAGE__MMAP_THRESHOLD_MB=1000 # Ng∆∞·ª°ng memory mapping      
      # B·∫£o m·∫≠t
      - QDRANT__SERVICE__ENABLE_CORS=true # B·∫≠t CORS (chia s·∫ª t√†i nguy√™n cross-origin)
      - QDRANT__CLUSTER__ENABLED=false # T·∫Øt ch·∫ø ƒë·ªô cluster (c·ª•m m√°y ch·ªß)
      - QDRANT__SERVICE__GRPC_TIMEOUT_MS=30000 # Timeout gRPC 30 gi√¢y
    # === PORT MAPPING ===
    ports:
      - "6333:6333" # HTTP API port
      - "6334:6334" # gRPC port (optional)
    # === VOLUME MOUNTS ===
    volumes:
      - qdrant_storage:/qdrant/storage # Vector data storage
      - qdrant_snapshots:/qdrant/snapshots # Backup snapshots
      - ./qdrant/config:/qdrant/config # Custom configuration
    # === HEALTH CHECK - ƒê√É T·ªêI ∆ØU H√ìA ===
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:6333/health" ]
      interval: 15s # Gi·∫£m t·ª´ 30s xu·ªëng 15s ƒë·ªÉ ph√°t hi·ªán s·ªõm
      timeout: 5s # Gi·∫£m t·ª´ 10s xu·ªëng 5s
      retries: 3 # Gi·ªØ nguy√™n 3 l·∫ßn th·ª≠
      start_period: 45s # TƒÉng t·ª´ 30s l√™n 45s cho vector DB
    # === RESOURCE LIMITS - ƒê√É T·ªêI ∆ØU H√ìA ===
    deploy:
      resources:
        limits:
          cpus: '8' # TƒÉng t·ª´ 4 l√™n 8 CPU cores cho vector operations
          memory: 16G # TƒÉng t·ª´ 8G l√™n 16GB RAM (vector DB c·∫ßn nhi·ªÅu RAM)
        reservations:
          cpus: '4' # TƒÉng t·ª´ 2 l√™n 4 CPU ƒë·∫£m b·∫£o
          memory: 8G # TƒÉng t·ª´ 4G l√™n 8GB RAM ƒë·∫£m b·∫£o
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=false" # Kh√¥ng expose qua Traefik (internal use)
      - "service.group=ai" # Nh√≥m service AI
      - "service.type=database" # Lo·∫°i service database
      - "backup.enable=true" # Enable backup cho vectors

  # Ollama CPU - Phi√™n b·∫£n Ollama cho CPU - ƒê√É T·ªêI ∆ØU H√ìA
  ollama-cpu:
    profiles: [ "cpu" ] # Ch·ªâ ch·∫°y khi s·ª≠ d·ª•ng profile cpu
    <<: *service-ollama
    container_name: ollama
    environment:
      # T·ªëi ∆∞u hi·ªáu su·∫•t CPU cho Ollama
      - OLLAMA_NUM_PARALLEL=4 # S·ªë l∆∞·ª£ng requests song song
      - OLLAMA_MAX_LOADED_MODELS=3 # S·ªë m√¥ h√¨nh t·ªëi ƒëa ƒë∆∞·ª£c load
      - OLLAMA_MAX_QUEUE=512 # K√≠ch th∆∞·ªõc queue t·ªëi ƒëa
      - OLLAMA_FLASH_ATTENTION=1 # B·∫≠t Flash Attention
      - OLLAMA_HOST=0.0.0.0 # L·∫Øng nghe t·∫•t c·∫£ interfaces
      - OLLAMA_ORIGINS=* # Cho ph√©p t·∫•t c·∫£ origins
      - OLLAMA_KEEP_ALIVE=5m # Th·ªùi gian gi·ªØ m√¥ h√¨nh trong memory
      - OLLAMA_LOAD_TIMEOUT=10m # Timeout khi load m√¥ h√¨nh
      - OLLAMA_REQUEST_TIMEOUT=5m # Timeout cho request
      - OLLAMA_CONCURRENCY=4 # S·ªë l∆∞·ª£ng concurrent requests
      - OLLAMA_RUNNERS_DIR=/tmp/ollama/runners # Th∆∞ m·ª•c runners
      - OLLAMA_TMPDIR=/tmp/ollama # Th∆∞ m·ª•c temporary
      # T·ªëi ∆∞u b·ªô nh·ªõ
      - OLLAMA_MAX_VRAM=0 # Kh√¥ng s·ª≠ d·ª•ng VRAM (CPU mode)
      - OLLAMA_CPU_THREADS=8 # S·ªë threads CPU
      - OLLAMA_NUMA=1 # B·∫≠t NUMA optimization
    ports:
      - "11434:11434" # Expose port Ollama
    deploy:
      resources:
        limits:
          cpus: '8' # TƒÉng t·ª´ 4 l√™n 8 CPU
          memory: 16G # TƒÉng t·ª´ 8G l√™n 16G RAM
        reservations:
          cpus: '4' # TƒÉng t·ª´ 2 l√™n 4 CPU
          memory: 8G # TƒÉng t·ª´ 4G l√™n 8G RAM

  # Ollama GPU - Phi√™n b·∫£n Ollama cho GPU NVIDIA
  ollama-gpu:
    profiles: [ "gpu-nvidia" ] # Ch·ªâ ch·∫°y khi s·ª≠ d·ª•ng profile gpu-nvidia
    <<: *service-ollama
    container_name: ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia # S·ª≠ d·ª•ng NVIDIA GPU
              count: 1 # S·ª≠ d·ª•ng 1 GPU
              capabilities: [ gpu ] # Y√™u c·∫ßu kh·∫£ nƒÉng GPU

  # Service t·∫£i m√¥ h√¨nh cho Ollama CPU
  ollama-pull-llama-cpu:
    profiles: [ "cpu" ]
    <<: *init-ollama
    container_name: ollama-pull-llama
    depends_on:
      - ollama-cpu # ƒê∆°n gi·∫£n h√≥a ph·ª• thu·ªôc
    restart: "no" # Ch·ªâ ch·∫°y m·ªôt l·∫ßn v√† kh√¥ng kh·ªüi ƒë·ªông l·∫°i

  # Service t·∫£i m√¥ h√¨nh cho Ollama GPU
  ollama-pull-llama-gpu:
    profiles: [ "gpu-nvidia" ]
    <<: *init-ollama
    container_name: ollama-pull-llama
    depends_on:
      - ollama-gpu # ƒê∆°n gi·∫£n h√≥a ph·ª• thu·ªôc
    restart: "no" # Ch·ªâ ch·∫°y m·ªôt l·∫ßn v√† kh√¥ng kh·ªüi ƒë·ªông l·∫°i

  # Redis - H·ªá th·ªëng cache (b·ªô nh·ªõ ƒë·ªám) in-memory - ƒê√É T·ªêI ∆ØU H√ìA
  redis:
    <<: *default-opts
    image: redis:7.2-alpine # S·ª≠ d·ª•ng phi√™n b·∫£n Alpine (Linux nh·∫π)
    container_name: redis
    # C·∫•u h√¨nh Redis t·ªëi ∆∞u v·ªõi maxmemory policy v√† persistence
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-nextflow@2025}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 3gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --databases 16
      --stop-writes-on-bgsave-error no
      --rdbcompression yes
      --rdbchecksum yes
      --dir /data
      --logfile ""
      --syslog-enabled no
      --hash-max-ziplist-entries 512
      --hash-max-ziplist-value 64
      --list-max-ziplist-size -2
      --set-max-intset-entries 512
      --zset-max-ziplist-entries 128
      --zset-max-ziplist-value 64
      --hll-sparse-max-bytes 3000
      --stream-node-max-bytes 4096
      --stream-node-max-entries 100
      --activerehashing yes
      --client-output-buffer-limit normal 0 0 0
      --client-output-buffer-limit replica 256mb 64mb 60
      --client-output-buffer-limit pubsub 32mb 8mb 60
      --hz 10
      --dynamic-hz yes
      --aof-rewrite-incremental-fsync yes
      --rdb-save-incremental-fsync yes
    ports:
      - "6379:6379" # M·ªü c·ªïng Redis
    volumes:
      - redis_data:/data # L∆∞u tr·ªØ d·ªØ li·ªáu b·ªÅn v·ªØng
    environment:
      - REDIS_REPLICATION_MODE=master # Ch·∫ø ƒë·ªô master
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 10s # TƒÉng t·ª´ 5s l√™n 10s ƒë·ªÉ gi·∫£m t·∫£i
      timeout: 5s
      retries: 3 # Gi·∫£m t·ª´ 5 xu·ªëng 3 l·∫ßn th·ª≠
      start_period: 15s # TƒÉng t·ª´ 10s l√™n 15s
    deploy:
      resources:
        limits:
          cpus: '2' # Gi·∫£m t·ª´ 4 xu·ªëng 2 CPU
          memory: 4G # Gi·ªØ nguy√™n 4GB
        reservations:
          cpus: '1' # Gi·∫£m t·ª´ 2 xu·ªëng 1 CPU
          memory: 2G # Gi·ªØ nguy√™n 2GB

  # Redis Commander - Giao di·ªán web ƒë·ªÉ qu·∫£n l√Ω Redis
  redis-commander:
    <<: *default-opts
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379:0:${REDIS_PASSWORD:-nextflow@2025}
      - HTTP_USER=${REDIS_COMMANDER_USER:-admin}
      - HTTP_PASSWORD=${REDIS_COMMANDER_PASSWORD:-nextflow@2025}
    ports:
      - "8082:8081" # Giao di·ªán web cho Redis Commander
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G

  # D·ªãch v·ª• sao l∆∞u t·ª± ƒë·ªông cho PostgreSQL
  backup:
    image: postgres:16-alpine
    container_name: backup
    restart: "no" # Ch·ªâ ch·∫°y m·ªôt l·∫ßn
    volumes:
      - ./backups/postgres:/backups # Th∆∞ m·ª•c l∆∞u tr·ªØ b·∫£n sao l∆∞u
    command: |
      bash -c '
      mkdir -p /backups
      export PGPASSWORD=$$POSTGRES_PASSWORD
      TIMESTAMP=$$(date +%Y%m%d_%H%M%S)

      echo "===== B·∫ÆT ƒê·∫¶U SAO L∆ØU POSTGRESQL ====="
      echo "Th·ªùi gian b·∫Øt ƒë·∫ßu: $$(date)"

      # Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn PostgreSQL
      echo "Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn PostgreSQL..."
      if ! pg_isready -h postgres -U $$POSTGRES_USER; then
        echo "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn PostgreSQL. ƒêang th·ª≠ l·∫°i..."
        sleep 10
        if ! pg_isready -h postgres -U $$POSTGRES_USER; then
          echo "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn PostgreSQL sau khi th·ª≠ l·∫°i. H·ªßy b·ªè sao l∆∞u."
          exit 1
        fi
      fi

      # Li·ªát k√™ c√°c c∆° s·ªü d·ªØ li·ªáu
      echo "C√°c c∆° s·ªü d·ªØ li·ªáu hi·ªán c√≥:"
      psql -h postgres -U $$POSTGRES_USER -c "\l"

      # Sao l∆∞u c∆° s·ªü d·ªØ li·ªáu ch√≠nh nextflow
      echo "ƒêang sao l∆∞u c∆° s·ªü d·ªØ li·ªáu nextflow..."
      pg_dump -h postgres -U $$POSTGRES_USER -d nextflow -F c -b -v -f /backups/nextflow_$$TIMESTAMP.backup

      # Sao l∆∞u c∆° s·ªü d·ªØ li·ªáu n8n
      echo "ƒêang sao l∆∞u c∆° s·ªü d·ªØ li·ªáu nextflow_n8n..."
      pg_dump -h postgres -U $$POSTGRES_USER -d nextflow_n8n -F c -b -v -f /backups/nextflow_n8n_$$TIMESTAMP.backup

      # Sao l∆∞u t·∫•t c·∫£ c√°c c∆° s·ªü d·ªØ li·ªáu
      echo "ƒêang sao l∆∞u t·∫•t c·∫£ c√°c c∆° s·ªü d·ªØ li·ªáu..."
      pg_dumpall -h postgres -U $$POSTGRES_USER -f /backups/all_databases_$$TIMESTAMP.sql

      # X√≥a c√°c t·ªáp sao l∆∞u c≈© h∆°n 7 ng√†y
      echo "ƒêang x√≥a c√°c t·ªáp sao l∆∞u c≈©..."
      find /backups -type f -mtime +7 -delete

      echo "Th·ªùi gian k·∫øt th√∫c: $$(date)"
      echo "===== HO√ÄN TH√ÄNH SAO L∆ØU POSTGRESQL ====="

      # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c t·ªáp sao l∆∞u ƒë√£ t·∫°o
      echo "C√°c t·ªáp sao l∆∞u ƒë√£ t·∫°o:"
      ls -lh /backups/

      # Hi·ªÉn th·ªã dung l∆∞·ª£ng th∆∞ m·ª•c sao l∆∞u
      echo "T·ªïng dung l∆∞·ª£ng th∆∞ m·ª•c sao l∆∞u:"
      du -sh /backups/
      '
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-root}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-nextflow@2025}
    networks:
      - demo
    depends_on:
      postgres:
        condition: service_healthy # Ch·ªâ ch·∫°y khi PostgreSQL ƒë√£ s·∫µn s√†ng
    profiles: [ "backup" ] # Ch·ªâ ch·∫°y khi s·ª≠ d·ª•ng profile sao l∆∞u

  # Cloudflare Tunnel "nextflow" - ƒê∆∞·ªùng h·∫ßm b·∫£o m·∫≠t cho d·ªãch v·ª• ch√≠nh
  cloudflare-tunnel:
    <<: *default-opts
    image: cloudflare/cloudflared:latest
    container_name: cloudflare-tunnel
    hostname: cloudflare-tunnel
    command: tunnel --config /etc/cloudflared/config.yml run
    volumes:
      - ./cloudflared/config/cloudflared-config.yml:/etc/cloudflared/config.yml
      - ./cloudflared/credentials/credentials.json:/etc/cloudflared/credentials.json
    environment:
      - TUNNEL_ORIGIN_CERT=/etc/cloudflared/credentials.json
      - NO_AUTOUPDATE=true # T·∫Øt t·ª± ƒë·ªông c·∫≠p nh·∫≠t
    networks:
      - demo
    extra_hosts:
      - "host.docker.internal:host-gateway" # K·∫øt n·ªëi ƒë·∫øn m√°y ch·ªß host
    depends_on:
      - wordpress
      - mariadb
    restart: unless-stopped

  # Prometheus - H·ªá th·ªëng thu th·∫≠p metrics (ch·ªâ s·ªë hi·ªáu nƒÉng)
  prometheus:
    <<: *default-opts
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle' # Cho ph√©p reload c·∫•u h√¨nh ƒë·ªông
    ports:
      - "9090:9090"
    volumes:
      - ./config/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G
    profiles: [ "monitoring" ]

  # Grafana - H·ªá th·ªëng hi·ªÉn th·ªã dashboard (b·∫£ng ƒëi·ªÅu khi·ªÉn tr·ª±c quan)
  grafana:
    <<: *default-opts
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3030:3000"
    volumes:
      - ./config/monitoring/grafana-dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
      - ./config/monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false # T·∫Øt ƒëƒÉng k√Ω t·ª± do
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G
    depends_on:
      prometheus:
        condition: service_healthy
    profiles: [ "monitoring" ]

  # Loki - H·ªá th·ªëng thu th·∫≠p logs (nh·∫≠t k√Ω h·ªá th·ªëng)
  loki:
    <<: *default-opts
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./config/monitoring/loki-config.yml:/etc/loki/loki-config.yml
      - loki_data:/loki
    command: -config.file=/etc/loki/loki-config.yml
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:3100/ready" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G
    profiles: [ "monitoring" ]

  # Promtail - Agent thu th·∫≠p logs t·ª´ c√°c container
  promtail:
    <<: *default-opts
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - ./config/monitoring/promtail-config.yml:/etc/promtail/promtail-config.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro # Ch·ªâ ƒë·ªçc logs container
      - /var/run/docker.sock:/var/run/docker.sock # K·∫øt n·ªëi Docker daemon
    command: -config.file=/etc/promtail/promtail-config.yml
    depends_on:
      loki:
        condition: service_healthy
    profiles: [ "monitoring" ]

  # Node Exporter - Thu th·∫≠p metrics t·ª´ m√°y ch·ªß host
  node-exporter:
    <<: *default-opts
    image: prom/node-exporter:latest
    container_name: node-exporter
    volumes:
      - /proc:/host/proc:ro # Th√¥ng tin ti·∫øn tr√¨nh
      - /sys:/host/sys:ro # Th√¥ng tin h·ªá th·ªëng
      - /:/rootfs:ro # Th√¥ng tin filesystem
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    profiles: [ "monitoring" ]

  # cAdvisor - Thu th·∫≠p metrics t·ª´ c√°c container Docker
  cadvisor:
    <<: *default-opts
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro # Root filesystem
      - /var/run:/var/run:ro # Runtime information
      - /sys:/sys:ro # System information
      - /var/lib/docker/:/var/lib/docker:ro # Docker data
      - /dev/disk/:/dev/disk:ro # Disk information
    ports:
      - "8081:8080"
    profiles: [ "monitoring" ]

  # RabbitMQ - H·ªá th·ªëng message queue (h√†ng ƒë·ª£i tin nh·∫Øn)
  rabbitmq:
    <<: *default-opts
    image: rabbitmq:3.12-management-alpine
    container_name: rabbitmq
    hostname: rabbitmq
    ports:
      - "5672:5672" # C·ªïng AMQP (giao th·ª©c tin nh·∫Øn)
      - "15672:15672" # C·ªïng giao di·ªán qu·∫£n l√Ω web
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-admin}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST:-/} # Virtual host m·∫∑c ƒë·ªãnh
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "check_port_connectivity" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G
    profiles: [ "messaging" ]
    
  # Jaeger - H·ªá th·ªëng distributed tracing (theo d√µi ph√¢n t√°n)
  jaeger:
    <<: *default-opts
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true # B·∫≠t OpenTelemetry Protocol
    ports:
      - "6831:6831/udp" # Jaeger thrift compact
      - "6832:6832/udp" # Jaeger thrift binary
      - "5778:5778" # Jaeger configs
      - "16686:16686" # Giao di·ªán web Jaeger
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "9411:9411" # Zipkin (t∆∞∆°ng th√≠ch)
    volumes:
      - jaeger_data:/badger
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:16686" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    profiles: [ "tracing" ]

  # MariaDB - C∆° s·ªü d·ªØ li·ªáu MySQL cho WordPress
  mariadb:
    <<: *default-opts
    image: mariadb:11.2
    container_name: mariadb
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=nextflow@2025 # M·∫≠t kh·∫©u root MySQL
      - MYSQL_DATABASE=nextflow # T√™n c∆° s·ªü d·ªØ li·ªáu
      - MYSQL_USER=admin # T√†i kho·∫£n ng∆∞·ªùi d√πng
      - MYSQL_PASSWORD=nextflow@2025 # M·∫≠t kh·∫©u ng∆∞·ªùi d√πng
    volumes:
      - mariadb_data:/var/lib/mysql # L∆∞u tr·ªØ d·ªØ li·ªáu b·ªÅn v·ªØng
    ports:
      - "3306:3306" # C·ªïng MySQL/MariaDB

    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  # WordPress - H·ªá th·ªëng qu·∫£n l√Ω n·ªôi dung (CMS) cho landing page
  wordpress:
    <<: *default-opts
    image: wordpress:6.8.1
    container_name: wordpress
    restart: always
    environment:
      - WORDPRESS_DB_HOST=mariadb # M√°y ch·ªß c∆° s·ªü d·ªØ li·ªáu
      - WORDPRESS_DB_NAME=nextflow # T√™n c∆° s·ªü d·ªØ li·ªáu
      - WORDPRESS_DB_USER=admin # T√†i kho·∫£n c∆° s·ªü d·ªØ li·ªáu
      - WORDPRESS_DB_PASSWORD=nextflow@2025 # M·∫≠t kh·∫©u c∆° s·ªü d·ªØ li·ªáu
      - WORDPRESS_TABLE_PREFIX=wp_ # Ti·ªÅn t·ªë b·∫£ng WordPress
    volumes:
      - wordpress_data:/var/www/html # D·ªØ li·ªáu WordPress
      - ./wordpress/themes:/var/www/html/wp-content/themes # Giao di·ªán
      - ./wordpress/plugins:/var/www/html/wp-content/plugins # Plugin
      - ./wordpress/uploads:/var/www/html/wp-content/uploads # T·ªáp t·∫£i l√™n
    ports:
      - "8080:80" # C·ªïng web WordPress
    depends_on:
      - mariadb

  # LANGFLOW - LOW-CODE AI WORKFLOW PLATFORM
  # ----------------------------------------------------------------------------
  langflow:
    <<: *default-opts
    image: langflowai/langflow:latest # S·ª≠ d·ª•ng phi√™n b·∫£n alpha stable
    container_name: langflow
    hostname: langflow # Hostname cho service discovery
    user: "0:0" # Run as root ƒë·ªÉ tr√°nh permission issues
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # C·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_DATABASE_URL=${LANGFLOW_DATABASE_URL}
      # C·∫•u h√¨nh b·∫£o m·∫≠t - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_SECRET_KEY=${LANGFLOW_SECRET_KEY}
      - LANGFLOW_JWT_SECRET=${LANGFLOW_JWT_SECRET}
      - LANGFLOW_SUPERUSER_PASSWORD=${LANGFLOW_SUPERUSER_PASSWORD}
      # C·∫•u h√¨nh m√°y ch·ªß - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_HOST=${LANGFLOW_HOST}
      - LANGFLOW_PORT=${LANGFLOW_PORT}
      - LANGFLOW_WORKERS=${LANGFLOW_WORKERS}
      - LANGFLOW_ENV=${LANGFLOW_ENV}
      # C·∫•u h√¨nh cache - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_CACHE_TYPE=${LANGFLOW_CACHE_TYPE}
      - LANGFLOW_CACHE_SIZE=${LANGFLOW_CACHE_SIZE}
      - LANGFLOW_REDIS_URL= # Disable Redis cache
      # C·∫•u h√¨nh ghi log - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_LOG_LEVEL=${LANGFLOW_LOG_LEVEL}
      - LANGFLOW_LOG_FILE=${LANGFLOW_LOG_FILE}
      - LANGFLOW_DISABLE_LOGS=${LANGFLOW_DISABLE_LOGS}
      # C·∫•u h√¨nh t√≠nh nƒÉng - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_AUTO_LOGIN=${LANGFLOW_AUTO_LOGIN}
      - LANGFLOW_NEW_USER_IS_ACTIVE=${LANGFLOW_NEW_USER_IS_ACTIVE}
      - LANGFLOW_MAX_FILE_SIZE_UPLOAD=${LANGFLOW_MAX_FILE_SIZE_UPLOAD}
      # C·∫•u h√¨nh th∆∞ m·ª•c - S·ª≠ d·ª•ng bi·∫øn t·ª´ .env
      - LANGFLOW_CONFIG_DIR=${LANGFLOW_CONFIG_DIR}
      - LANGFLOW_CACHE_DIR=${LANGFLOW_CACHE_DIR}
      - LANGFLOW_STORE_ENVIRONMENT_VARIABLES=${LANGFLOW_STORE_ENVIRONMENT_VARIABLES}
      - LANGFLOW_SAVE_DB_IN_CONFIG_DIR=${LANGFLOW_SAVE_DB_IN_CONFIG_DIR}
    # === PORT MAPPING ===
    ports:
      - "7860:7860" # Langflow web interface
    # === VOLUME MOUNTS ===
    volumes:
      - langflow_data:/app/data # Persistent data storage
      - langflow_logs:/app/logs # Log files
      - ./langflow/flows:/app/flows # Custom flows directory
      - ./langflow/components:/app/components # Custom components
      - ./shared:/data/shared # Shared folder
    # === DEPENDENCIES ===
    depends_on:
      postgres:
        condition: service_healthy # ƒê·ª£i PostgreSQL s·∫µn s√†ng
      redis:
        condition: service_healthy # ƒê·ª£i Redis s·∫µn s√†ng
    # === NETWORK CONFIGURATION ===
    networks:
      - demo
    # === HOST MAPPING ƒë·ªÉ fix DNS issues ===
    extra_hosts:
      - "postgres:host-gateway" # Map postgres hostname to host
      - "redis:host-gateway" # Map redis hostname to host
      - "host.docker.internal:host-gateway" # Ensure host connectivity
    # === HEALTH CHECK ===
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:7860/health" ]
      interval: 30s # Ki·ªÉm tra m·ªói 30 gi√¢y
      timeout: 10s # Timeout sau 10 gi√¢y
      retries: 3 # Th·ª≠ l·∫°i 3 l·∫ßn
      start_period: 60s # ƒê·ª£i 60 gi√¢y tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu check
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '4' # T·ªëi ƒëa 4 CPU cores
          memory: 6G # T·ªëi ƒëa 6GB RAM
        reservations:
          cpus: '2' # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 CPU
          memory: 4G # ƒê·∫£m b·∫£o √≠t nh·∫•t 2GB RAM
    # === LABELS FOR MONITORING ===
    labels:
      - "traefik.enable=true" # Enable Traefik routing
      - "service.group=ai" # Nh√≥m service AI
      - "service.type=frontend" # Lo·∫°i service frontend
      - "backup.enable=true" # Enable backup cho workflows
    # === PROFILE ===
    profiles: [ "langflow" ] # Ch·ªâ ch·∫°y khi s·ª≠ d·ª•ng profile ai ho·∫∑c langflow

  # ============================================================================
  # GITLAB CE - H·ªÜ TH·ªêNG QU·∫¢N L√ù M√É NGU·ªíN V√Ä CI/CD (CUSTOM BUILD)
  # ============================================================================
  gitlab:
    <<: *default-opts
    build:
      context: ./gitlab/docker
      dockerfile: Dockerfile
      args:
        - GITLAB_VERSION=${GITLAB_VERSION:-16.11.10-ce.0}
        - GITLAB_TIMEZONE=Asia/Ho_Chi_Minh
    image: nextflow/gitlab-ce:${GITLAB_VERSION:-16.11.10-ce.0}
    container_name: gitlab
    hostname: gitlab
    restart: unless-stopped
    # === C·∫§U H√åNH ENVIRONMENT ===
    environment:
      # C·∫•u h√¨nh GitLab Omnibus
      GITLAB_OMNIBUS_CONFIG: |
        # === C·∫§U H√åNH C∆† B·∫¢N ===
        external_url '${GITLAB_EXTERNAL_URL:-http://localhost:8088}';
        gitlab_kas['enable'] = false;
        gitlab_rails['initial_root_password'] = "${GITLAB_ROOT_PASSWORD:-Nextflow@2025}";
        gitlab_rails['time_zone'] = 'Asia/Ho_Chi_Minh';
        # === C·∫§U H√åNH C∆† S·ªû D·ªÆ LI·ªÜU ===
        postgresql['enable'] = false;
        gitlab_rails['db_adapter'] = 'postgresql';
        gitlab_rails['db_encoding'] = 'utf8';
        gitlab_rails['db_host'] = 'postgres';
        gitlab_rails['db_port'] = 5432;
        gitlab_rails['db_username'] = '${POSTGRES_USER:-nextflow}';
        gitlab_rails['db_password'] = '${POSTGRES_PASSWORD:-nextflow@2025}';
        gitlab_rails['db_database'] = '${GITLAB_DATABASE:-nextflow_gitlab}';
        # === C·∫§U H√åNH REDIS ===
        redis['enable'] = false;
        gitlab_rails['redis_host'] = 'redis';
        gitlab_rails['redis_port'] = 6379;
        gitlab_rails['redis_password'] = '${REDIS_PASSWORD:-nextflow@2025}';
        # === C·∫§U H√åNH SSH ===
        gitlab_rails['gitlab_shell_ssh_port'] = ${GITLAB_SSH_PORT:-2222};
        # === C·∫§U H√åNH CONTAINER REGISTRY ===
        registry_external_url '${GITLAB_REGISTRY_URL:-http://localhost:5050}';
        gitlab_rails['registry_enabled'] = true;
        registry_nginx['listen_port'] = ${GITLAB_REGISTRY_PORT:-5050};
        # === C·∫§U H√åNH EMAIL (STALWART MAIL) ===
        gitlab_rails['smtp_enable'] = ${GITLAB_SMTP_ENABLE:-true};
        gitlab_rails['smtp_address'] = '${MAIL_SMTP_HOST:-stalwart-mail}';
        gitlab_rails['smtp_port'] = ${MAIL_SMTP_PORT:-587};
        gitlab_rails['smtp_user_name'] = '${MAIL_SMTP_USER:-gitlab@nextflow.local}';
        gitlab_rails['smtp_password'] = '${MAIL_SMTP_PASSWORD:-changeme123}';
        gitlab_rails['smtp_domain'] = '${MAIL_DOMAIN:-nextflow.local}';
        gitlab_rails['smtp_authentication'] = 'login';
        gitlab_rails['smtp_enable_starttls_auto'] = true;
        gitlab_rails['smtp_tls'] = false;
        gitlab_rails['gitlab_email_from'] = '${MAIL_FROM:-gitlab@nextflow.local}';
        gitlab_rails['gitlab_email_display_name'] = 'GitLab NextFlow CRM-AI';
        gitlab_rails['gitlab_email_reply_to'] = '${MAIL_REPLY_TO:-noreply@nextflow.local}';
        # === C·∫§U H√åNH BACKUP ===
        gitlab_rails['backup_path'] = "/var/opt/gitlab/backups";
        gitlab_rails['backup_keep_time'] = ${GITLAB_BACKUP_KEEP_TIME:-604800};
        # === C·∫§U H√åNH HI·ªÜU SU·∫§T ===
        puma['worker_processes'] = ${GITLAB_PUMA_WORKERS:-4};
        puma['min_threads'] = ${GITLAB_PUMA_MIN_THREADS:-4};
        puma['max_threads'] = ${GITLAB_PUMA_MAX_THREADS:-16};
        sidekiq['max_concurrency'] = ${GITLAB_SIDEKIQ_CONCURRENCY:-10};
        # === T·∫ÆT MONITORING T√çCH H·ª¢P ===
        prometheus_monitoring['enable'] = false;
        # === C·∫§U H√åNH T√çNH NƒÇNG M·∫∂C ƒê·ªäNH ===
        gitlab_rails['gitlab_default_projects_features_issues'] = true;
        gitlab_rails['gitlab_default_projects_features_merge_requests'] = true;
        gitlab_rails['gitlab_default_projects_features_wiki'] = true;
        gitlab_rails['gitlab_default_projects_features_snippets'] = true;
        gitlab_rails['gitlab_default_projects_features_builds'] = true;
        gitlab_rails['gitlab_default_projects_features_container_registry'] = true;
        # === C·∫§U H√åNH CI/CD ===
        gitlab_rails['auto_devops_enabled'] = true;
        gitlab_rails['shared_runners_enabled'] = true;
        # === C·∫§U H√åNH B·∫¢O M·∫¨T ===
        gitlab_rails['signup_enabled'] = ${GITLAB_SIGNUP_ENABLED:-true};
        gitlab_rails['require_admin_approval_after_user_signup'] = false;
        gitlab_rails['send_user_confirmation_email'] = false;
    # === PORT MAPPING ===
    ports:
      - "${GITLAB_HTTP_PORT:-8088}:80"        # HTTP Web interface
      - "${GITLAB_HTTPS_PORT:-8443}:443"      # HTTPS Web interface
      - "${GITLAB_SSH_PORT:-2222}:22"         # SSH Git access
      - "${GITLAB_REGISTRY_PORT:-5050}:5050"  # Container Registry
    # === VOLUME MOUNTS ===
    volumes:
      # Persistent data storage
      - ./gitlab/config:/etc/gitlab
      - ./gitlab/logs:/var/log/gitlab
      - ./gitlab/data:/var/opt/gitlab
      - ./gitlab/backups:/var/opt/gitlab/backups
      # Scripts t√πy ch·ªânh
      - ./scripts:/opt/nextflow/scripts:ro
    # === DEPENDENCIES ===
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    # === HEALTH CHECK ===
    healthcheck:
      test: ["CMD", "/opt/gitlab/bin/gitlab-healthcheck", "--fail", "--max-time", "10"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 300s  # GitLab c·∫ßn th·ªùi gian kh·ªüi ƒë·ªông l√¢u
    # === RESOURCE LIMITS ===
    deploy:
      resources:
        limits:
          cpus: '${GITLAB_CPU_LIMIT:-4}'
          memory: ${GITLAB_MEMORY_LIMIT:-8G}
        reservations:
          cpus: '${GITLAB_CPU_RESERVE:-2}'
          memory: ${GITLAB_MEMORY_RESERVE:-4G}
    # === LABELS ===
    labels:
      - "service.group=devops"
      - "service.type=git"
      - "backup.enable=true"
      - "backup.schedule=daily"
    # === PROFILE ===
    profiles: ["gitlab"]

  # ================================
  # STALWART MAIL SERVER
  # ================================
  stalwart-mail:
    image: stalwartlabs/mail-server:latest
    container_name: stalwart-mail
    restart: unless-stopped
    hostname: ${MAIL_HOSTNAME:-mail.localhost}
    environment:
      # C·∫•u h√¨nh c∆° b·∫£n
      - STALWART_HOSTNAME=${MAIL_HOSTNAME:-mail.localhost}
      - STALWART_ADMIN_USER=${MAIL_ADMIN_USER:-admin}
      - STALWART_ADMIN_PASSWORD=${MAIL_ADMIN_PASSWORD:-changeme123}
      # C·∫•u h√¨nh database
      - STALWART_DB_TYPE=postgresql
      - STALWART_DB_HOST=postgres
      - STALWART_DB_PORT=5432
      - STALWART_DB_NAME=${MAIL_DB_NAME:-stalwart_mail}
      - STALWART_DB_USER=${MAIL_DB_USER:-stalwart}
      - STALWART_DB_PASSWORD=${MAIL_DB_PASSWORD:-stalwart123}
      # C·∫•u h√¨nh SMTP
      - STALWART_SMTP_PORT=25
      - STALWART_SMTP_SUBMISSION_PORT=587
      - STALWART_SMTP_SUBMISSIONS_PORT=465
      # C·∫•u h√¨nh IMAP/POP3
      - STALWART_IMAP_PORT=143
      - STALWART_IMAPS_PORT=993
      - STALWART_POP3_PORT=110
      - STALWART_POP3S_PORT=995
      # C·∫•u h√¨nh b·∫£o m·∫≠t
      - STALWART_TLS_CERT_PATH=/etc/stalwart/certs/cert.pem
      - STALWART_TLS_KEY_PATH=/etc/stalwart/certs/key.pem
      - STALWART_DKIM_ENABLED=true
      - STALWART_SPF_ENABLED=true
      - STALWART_DMARC_ENABLED=true
      # C·∫•u h√¨nh ch·ªëng spam
      - STALWART_SPAM_FILTER_ENABLED=true
      - STALWART_ANTIVIRUS_ENABLED=true
      # C·∫•u h√¨nh logging
      - STALWART_LOG_LEVEL=${MAIL_LOG_LEVEL:-info}
      - STALWART_LOG_FORMAT=json
    ports:
      # SMTP Ports
      - "${MAIL_SMTP_PORT:-25}:25" # SMTP
      - "${MAIL_SUBMISSION_PORT:-587}:587" # SMTP Submission
      - "${MAIL_SUBMISSIONS_PORT:-465}:465" # SMTP Submissions (SSL)
      # IMAP Ports
      - "${MAIL_IMAP_PORT:-143}:143" # IMAP
      - "${MAIL_IMAPS_PORT:-993}:993" # IMAPS (SSL)
      # POP3 Ports
      - "${MAIL_POP3_PORT:-110}:110" # POP3
      - "${MAIL_POP3S_PORT:-995}:995" # POP3S (SSL)
      # Web Admin Interface
      - "${MAIL_ADMIN_PORT:-8080}:8080" # Web Admin
      # ManageSieve
      - "${MAIL_SIEVE_PORT:-4190}:4190" # ManageSieve
    volumes:
      # C·∫•u h√¨nh
      - stalwart_config:/etc/stalwart
      - stalwart_data:/var/lib/stalwart
      - stalwart_logs:/var/log/stalwart
      # SSL Certificates (n·∫øu c√≥)
      - ./stalwart/certs:/etc/stalwart/certs:ro
      # Custom configuration
      - ./stalwart/config:/etc/stalwart/config:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "stalwart-mail", "--config", "/etc/stalwart/stalwart-mail.toml", "--test" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G
    networks:
      - nextflow-network
    profiles: [ "mail" ]
